import torch


import torch.nn as nn


linear = nn.Linear(in_features=5, out_features=10)
# Shape of weight matrix -> out_features x in_features
# shape of bias vector is out_vecots
linear


X = torch.rand(20,5)
X.shape


out = linear(X)
out.shape


for param in linear.parameters():
    print(param.shape)


for name, param in linear.named_parameters():
    print(name, param.shape)


linear.weight.shape, linear.bias.shape


# X @ W.T + b
X.shape, linear.weight.T.shape

out_manual = (X @ linear.weight.T) + linear.bias
out_manual.shape


out = linear(X)
out.shape


torch.equal(out_manual, out)


linear(X)
linear.__call__(X)
linear.forward(X)

# Callable function nn -> linear -> __call__ -> forward


relu = nn.ReLU()
relu


list(relu.named_parameters())

x = torch.tensor([1., -2., 3., -4.])
relu(x)


# Softmax
# Softmax along dim 

soft = nn.Softmax(dim=1)

X = torch.tensor([
    [1., 2., 1.],
    [2., 2., 3.]
])
out = soft(X)
out


y_hat = out.argmax(dim=1)
y_hat


loss_fn = nn.CrossEntropyLoss()
# y is the true tables
# loss_fn(y_hat, y)
#loss_fn(inputs, targets)
# inputs, targets

# inputs need to be logits (pre-softmax values, pre-activation at the output layes)
# targets have to be scalars and not one hot encoded 


y = torch.tensor([0,1])
logits = torch.tensor([
    [1., 3., 4.],
    [2., 5., 1.]
])
logits.shape, y.shape


prob = soft(logits)
prob


(-torch.log(prob[0,0]) - torch.log(prob[1,1])) / 2


loss_fn = nn.CrossEntropyLoss()
loss_fn(logits, y)


# Cross entropy coverts into softmax, then computes loss


# Optimizers


from torch.optim import Adam # we also have many more adagrad etc etc etc a lot 


# Dataset


from torchvision import datasets
train_data = datasets.MNIST(
    root='data',
    download=True,
    train=True
)
test_data = datasets.MNIST(
    root='data',
    download=True,
    train=False
)


from torchvision.transforms import ToTensor

train_data = datasets.MNIST(
    root='data',
    train=True,
    transform=ToTensor()
)
test_data = datasets.MNIST(
    root='data',
    train=False,
    transform=ToTensor()
)



from torch.utils.data import DataLoader












flatten = nn.Flatten()


train_loader = DataLoader(train_data, batch_size=64)
test_loader = DataLoader(test_data, batch_size=64)

X, y = next(iter(train_loader))
X.shape, y.shape


# One hidden layer (fully connected layer)
# 784 features as input
# 256 neurons in the hidden layer



#nn.Module is a parent class
#Every class in nn is written in this

class ANN(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear = nn.Linear(
            in_features=784, out_features=256
        )
        self.relu = nn.ReLU()
        self.output = nn.Linear(
            in_features=256, out_features=10
        )
    def forward(self, X):
        X = self.flatten(X)
        X = self.linear(X)
        X = self.relu(X)
        X = self.output(X)
        return X

model = ANN()
model
        
        


from torchviz import make_dot
graph = make_dot(model, dict(model.named_parameters()))


print(X.shape)
out = model(X)
print(out.shape)
out[0]


l1 = relu(X.flatten(start_dim=1) @ model.linear.weight.T + model.linear.bias)
l2 = l1 @ model.output.weight.T + model.output.bias
l2.shape


torch.allclose(model(X), l2)


X.shape


# Network achitecture and the model
# Train loop
# Test loop
# Main body -> optimixer, loss function and the network


optim = Adam(model.parameters(), lr=0.001)
optim


loss_fn = nn.CrossEntropyLoss()


def train_loop(train_loader, model, loss_fn, optim):
    model.train() #Training mode ex if had dropout, behaviour is diff in inference and taining sits in nn.Module
    for batch , (X,y) in enumerate(train_loader):
        logits = model(X)
        loss = loss_fn(logits, y)
        loss.backward()
        optim.step()
        optim.zero_grad()
        if batch % 100 == 0:
            print(f'Train loss after batch {batch} is {loss}')
        


def test_loop(test_loader, model):
    model.eval() # evaluation model
    correct = 0
    with torch.no_grad():
        for (X,y) in test_loader:
            logits = model(X)
            y_hat = logits.argmax(dim=1)
            correct += (y == y_hat).type(torch.float).sum().item()
    size = len(test_loader.dataset)
    acc = correct / size
    print(f'Accuracy = {acc:2f}')


# Accuracy
y = torch.tensor([1,0,2,3])
y_hat = torch.tensor([0,0,1,3])
(y==y_hat).type(torch.float).sum().item()


model = ANN()
loss_fn = nn.CrossEntropyLoss()
optim = Adam(model.parameters(), lr=0.001)
epochs = 5

for epoch in range(epochs):
    print(f'Epoch {epoch + 1}')
    train_loop(train_loader, model, loss_fn, optim)
    test_loop(test_loader, model)
    


torch.save(model.state_dict(), 'ann.pt')


model = ANN()
state_dict = torch.load('ann.pt')
model.load_state_dict(state_dict)
model


print("CUDA available:", torch.cuda.is_available())
print("Current device index:", torch.cuda.current_device())
print("Device name:", torch.cuda.get_device_name(torch.cuda.current_device()))


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)
next(model.parameters()).device



# cpu 

n = 4096
cpu_a = torch.rand(n, n, device='cpu')
cpu_b = torch.rand(n, n, device='cpu')

%timeit cpu_a @ cpu_b


n = 4096
gpu_a = torch.rand(n, n, device='cuda')
gpu_b = torch.rand(n, n, device='cuda')

_ = gpu_a @ gpu_b
torch.cuda.synchronize()

%timeit gpu_a @ gpu_b; torch.cuda.synchronize()


model_gpu = ANN().to(device)
loss_fn = nn.CrossEntropyLoss()
optim = Adam(model_gpu.parameters(), lr=0.001)


torch.accelerator.current_accelerator().type


def train_loop(train_loader, model, loss_fn, optim):
    model_gpu.train() #Training mode ex if had dropout, behaviour is diff in inference and taining sits in nn.Module
    for batch , (X,y) in enumerate(train_loader):
        X, y = X.to('cuda'), y.to('cuda')
        logits = model_gpu(X)
        loss = loss_fn(logits, y)
        loss.backward()
        optim.step()
        optim.zero_grad()
        if batch % 100 == 0:
            print(f'Train loss after batch {batch} is {loss}')


def test_loop(test_loader, model):
    model_gpu.eval() # evaluation model
    correct = 0
    with torch.no_grad():
        for (X,y) in test_loader:
            X,y = X.to('cuda'), y.to('cuda')
            logits = model_gpu(X)
            y_hat = logits.argmax(dim=1)
            correct += (y == y_hat).type(torch.float).sum().item()
    size = len(test_loader.dataset)
    acc = correct / size
    print(f'Accuracy = {acc:2f}')


model_gpu = ANN().to('cuda')
loss_fn = nn.CrossEntropyLoss()
optim = Adam(model_gpu.parameters(), lr=0.001)
epochs = 5

for epoch in range(epochs):
    print(f'Epoch {epoch + 1}')
    train_loop(train_loader, model_gpu, loss_fn, optim)
    test_loop(test_loader, model_gpu)



model.eval()

X, y = test_data[0]      # first image + true label
print("True label:", y)
X = X.unsqueeze(0)  # add batch dimension & move to GPU
with torch.no_grad():
    logits = model(X)
    pred = logits.argmax(dim=1).item()
print("Predicted label:", pred)



import matplotlib.pyplot as plt

plt.imshow(test_data[0][0].squeeze(), cmap="gray")
plt.title(f"Predicted: {pred}, True: {y}")
plt.show()



